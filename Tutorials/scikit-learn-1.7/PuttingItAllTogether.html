<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>PuttingItAllTogether</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { color: #008000; } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { color: #008000; font-weight: bold; } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
<p><a href="ScikitLearnTutorials.html">scikit-learn tutorials
index</a></p>
<h1 id="putting-it-all-together">Putting it all together</h1>
<h2 id="pipelining">Pipelining</h2>
<p>We have seen that some estimators can transform data and that some
estimators can predict variables. We can also create combined
estimators:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a pipeline to search for the best combination of PCA truncation</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># and classifier regularization.</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA()</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a Standard Scaler to normalize inputs</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># set the tolerance to a large value to make the example faster</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>logistic <span class="op">=</span> LogisticRegression(max_iter<span class="op">=</span><span class="dv">10000</span>, tol<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>pipe <span class="op">=</span> Pipeline(steps<span class="op">=</span>[(<span class="st">&quot;scaler&quot;</span>, scaler), (<span class="st">&quot;pca&quot;</span>, pca), (<span class="st">&quot;logistic&quot;</span>, logistic)])</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>X_digits, y_digits <span class="op">=</span> datasets.load_digits(return_X_y<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters of pipelines can be set using &#39;__&#39; separated parameter names:</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;pca__n_components&quot;</span>: [<span class="dv">5</span>, <span class="dv">15</span>, <span class="dv">30</span>, <span class="dv">45</span>, <span class="dv">60</span>],</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;logistic__C&quot;</span>: np.logspace(<span class="op">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>),</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>search <span class="op">=</span> GridSearchCV(pipe, param_grid, n_jobs<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>search.fit(X_digits, y_digits)</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best parameter (CV score=</span><span class="sc">%0.3f</span><span class="st">):&quot;</span> <span class="op">%</span> search.best_score_)</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(search.best_params_)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the PCA spectrum</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>pca.fit(X_digits)</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>fig, (ax0, ax1) <span class="op">=</span> plt.subplots(nrows<span class="op">=</span><span class="dv">2</span>, sharex<span class="op">=</span><span class="va">True</span>, figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>ax0.plot(</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>    np.arange(<span class="dv">1</span>, pca.n_components_ <span class="op">+</span> <span class="dv">1</span>), pca.explained_variance_ratio_, <span class="st">&quot;+&quot;</span>, linewidth<span class="op">=</span><span class="dv">2</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>ax0.set_ylabel(<span class="st">&quot;PCA explained variance ratio&quot;</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>ax0.axvline(</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>    search.best_estimator_.named_steps[<span class="st">&quot;pca&quot;</span>].n_components,</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>    linestyle<span class="op">=</span><span class="st">&quot;:&quot;</span>,</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">&quot;n_components chosen&quot;</span>,</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>ax0.legend(prop<span class="op">=</span><span class="bu">dict</span>(size<span class="op">=</span><span class="dv">12</span>))</span></code></pre></div>
<p><a
href="https://scikit-learn.org/1.7/auto_examples/compose/plot_digits_pipe.html" target="_blank"><img
src="https://scikit-learn.org/1.7/_images/sphx_glr_plot_digits_pipe_001.png"
alt="../../_images/sphx_glr_plot_digits_pipe_001.png" /></a></p>
<h2 id="face-recognition-with-eigenfaces">Face recognition with
eigenfaces</h2>
<p>The dataset used in this example is a preprocessed excerpt of the
“Labeled Faces in the Wild”, also known as <a
href="http://vis-www.cs.umass.edu/lfw/" target="_blank">LFW</a>:</p>
<p><a href="http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz" target="_blank">Download
LFW dataset</a> (233MB)</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co">===================================================</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">Faces recognition example using eigenfaces and SVMs</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">===================================================</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">The dataset used in this example is a preprocessed excerpt of the</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;Labeled Faces in the Wild&quot;, aka LFW_:</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">  http://vis-www.cs.umass.edu/lfw/lfw-funneled.tgz (233MB)</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">.. _LFW: http://vis-www.cs.umass.edu/lfw/</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">&quot;&quot;&quot;</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> time <span class="im">import</span> time</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> loguniform</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> fetch_lfw_people</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> ConfusionMatrixDisplay, classification_report</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV, train_test_split</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Download the data, if not already on disk and load it as numpy arrays</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>lfw_people <span class="op">=</span> fetch_lfw_people(min_faces_per_person<span class="op">=</span><span class="dv">70</span>, resize<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co"># introspect the images arrays to find the shapes (for plotting)</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>n_samples, h, w <span class="op">=</span> lfw_people.images.shape</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="co"># for machine learning we use the 2 data directly (as relative pixel</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="co"># positions info is ignored by this model)</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> lfw_people.data</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>n_features <span class="op">=</span> X.shape[<span class="dv">1</span>]</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="co"># the label to predict is the id of the person</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> lfw_people.target</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>target_names <span class="op">=</span> lfw_people.target_names</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>n_classes <span class="op">=</span> target_names.shape[<span class="dv">0</span>]</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Total dataset size:&quot;</span>)</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;n_samples: </span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> n_samples)</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;n_features: </span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> n_features)</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;n_classes: </span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> n_classes)</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Split into a training set and a test and keep 25% of the data for testing.</span></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.25</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a>scaler <span class="op">=</span> StandardScaler()</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> scaler.fit_transform(X_train)</span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a>X_test <span class="op">=</span> scaler.transform(X_test)</span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a><span class="co"># Compute a PCA (eigenfaces) on the face dataset (treated as unlabeled</span></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a><span class="co"># dataset): unsupervised feature extraction / dimensionality reduction</span></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a>n_components <span class="op">=</span> <span class="dv">150</span></span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-68"><a href="#cb2-68" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(</span>
<span id="cb2-69"><a href="#cb2-69" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Extracting the top </span><span class="sc">%d</span><span class="st"> eigenfaces from </span><span class="sc">%d</span><span class="st"> faces&quot;</span> <span class="op">%</span> (n_components, X_train.shape[<span class="dv">0</span>])</span>
<span id="cb2-70"><a href="#cb2-70" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-71"><a href="#cb2-71" aria-hidden="true" tabindex="-1"></a>t0 <span class="op">=</span> time()</span>
<span id="cb2-72"><a href="#cb2-72" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA(n_components<span class="op">=</span>n_components, svd_solver<span class="op">=</span><span class="st">&quot;randomized&quot;</span>, whiten<span class="op">=</span><span class="va">True</span>).fit(X_train)</span>
<span id="cb2-73"><a href="#cb2-73" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;done in </span><span class="sc">%0.3f</span><span class="st">s&quot;</span> <span class="op">%</span> (time() <span class="op">-</span> t0))</span>
<span id="cb2-74"><a href="#cb2-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-75"><a href="#cb2-75" aria-hidden="true" tabindex="-1"></a>eigenfaces <span class="op">=</span> pca.components_.reshape((n_components, h, w))</span>
<span id="cb2-76"><a href="#cb2-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-77"><a href="#cb2-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Projecting the input data on the eigenfaces orthonormal basis&quot;</span>)</span>
<span id="cb2-78"><a href="#cb2-78" aria-hidden="true" tabindex="-1"></a>t0 <span class="op">=</span> time()</span>
<span id="cb2-79"><a href="#cb2-79" aria-hidden="true" tabindex="-1"></a>X_train_pca <span class="op">=</span> pca.transform(X_train)</span>
<span id="cb2-80"><a href="#cb2-80" aria-hidden="true" tabindex="-1"></a>X_test_pca <span class="op">=</span> pca.transform(X_test)</span>
<span id="cb2-81"><a href="#cb2-81" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;done in </span><span class="sc">%0.3f</span><span class="st">s&quot;</span> <span class="op">%</span> (time() <span class="op">-</span> t0))</span>
<span id="cb2-82"><a href="#cb2-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-83"><a href="#cb2-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-84"><a href="#cb2-84" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-85"><a href="#cb2-85" aria-hidden="true" tabindex="-1"></a><span class="co"># Train a SVM classification model</span></span>
<span id="cb2-86"><a href="#cb2-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-87"><a href="#cb2-87" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Fitting the classifier to the training set&quot;</span>)</span>
<span id="cb2-88"><a href="#cb2-88" aria-hidden="true" tabindex="-1"></a>t0 <span class="op">=</span> time()</span>
<span id="cb2-89"><a href="#cb2-89" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb2-90"><a href="#cb2-90" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;C&quot;</span>: loguniform(<span class="fl">1e3</span>, <span class="fl">1e5</span>),</span>
<span id="cb2-91"><a href="#cb2-91" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;gamma&quot;</span>: loguniform(<span class="fl">1e-4</span>, <span class="fl">1e-1</span>),</span>
<span id="cb2-92"><a href="#cb2-92" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb2-93"><a href="#cb2-93" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> RandomizedSearchCV(</span>
<span id="cb2-94"><a href="#cb2-94" aria-hidden="true" tabindex="-1"></a>    SVC(kernel<span class="op">=</span><span class="st">&quot;rbf&quot;</span>, class_weight<span class="op">=</span><span class="st">&quot;balanced&quot;</span>), param_grid, n_iter<span class="op">=</span><span class="dv">10</span></span>
<span id="cb2-95"><a href="#cb2-95" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-96"><a href="#cb2-96" aria-hidden="true" tabindex="-1"></a>clf <span class="op">=</span> clf.fit(X_train_pca, y_train)</span>
<span id="cb2-97"><a href="#cb2-97" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;done in </span><span class="sc">%0.3f</span><span class="st">s&quot;</span> <span class="op">%</span> (time() <span class="op">-</span> t0))</span>
<span id="cb2-98"><a href="#cb2-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Best estimator found by grid search:&quot;</span>)</span>
<span id="cb2-99"><a href="#cb2-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(clf.best_estimator_)</span>
<span id="cb2-100"><a href="#cb2-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-101"><a href="#cb2-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-102"><a href="#cb2-102" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-103"><a href="#cb2-103" aria-hidden="true" tabindex="-1"></a><span class="co"># Quantitative evaluation of the model quality on the test set</span></span>
<span id="cb2-104"><a href="#cb2-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-105"><a href="#cb2-105" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Predicting people&#39;s names on the test set&quot;</span>)</span>
<span id="cb2-106"><a href="#cb2-106" aria-hidden="true" tabindex="-1"></a>t0 <span class="op">=</span> time()</span>
<span id="cb2-107"><a href="#cb2-107" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> clf.predict(X_test_pca)</span>
<span id="cb2-108"><a href="#cb2-108" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;done in </span><span class="sc">%0.3f</span><span class="st">s&quot;</span> <span class="op">%</span> (time() <span class="op">-</span> t0))</span>
<span id="cb2-109"><a href="#cb2-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-110"><a href="#cb2-110" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(classification_report(y_test, y_pred, target_names<span class="op">=</span>target_names))</span>
<span id="cb2-111"><a href="#cb2-111" aria-hidden="true" tabindex="-1"></a>ConfusionMatrixDisplay.from_estimator(</span>
<span id="cb2-112"><a href="#cb2-112" aria-hidden="true" tabindex="-1"></a>    clf, X_test_pca, y_test, display_labels<span class="op">=</span>target_names, xticks_rotation<span class="op">=</span><span class="st">&quot;vertical&quot;</span></span>
<span id="cb2-113"><a href="#cb2-113" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-114"><a href="#cb2-114" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb2-115"><a href="#cb2-115" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-116"><a href="#cb2-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-117"><a href="#cb2-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-118"><a href="#cb2-118" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-119"><a href="#cb2-119" aria-hidden="true" tabindex="-1"></a><span class="co"># Qualitative evaluation of the predictions using matplotlib</span></span>
<span id="cb2-120"><a href="#cb2-120" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-121"><a href="#cb2-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-122"><a href="#cb2-122" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_gallery(images, titles, h, w, n_row<span class="op">=</span><span class="dv">3</span>, n_col<span class="op">=</span><span class="dv">4</span>):</span>
<span id="cb2-123"><a href="#cb2-123" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Helper function to plot a gallery of portraits&quot;&quot;&quot;</span></span>
<span id="cb2-124"><a href="#cb2-124" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="fl">1.8</span> <span class="op">*</span> n_col, <span class="fl">2.4</span> <span class="op">*</span> n_row))</span>
<span id="cb2-125"><a href="#cb2-125" aria-hidden="true" tabindex="-1"></a>    plt.subplots_adjust(bottom<span class="op">=</span><span class="dv">0</span>, left<span class="op">=</span><span class="fl">0.01</span>, right<span class="op">=</span><span class="fl">0.99</span>, top<span class="op">=</span><span class="fl">0.90</span>, hspace<span class="op">=</span><span class="fl">0.35</span>)</span>
<span id="cb2-126"><a href="#cb2-126" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n_row <span class="op">*</span> n_col):</span>
<span id="cb2-127"><a href="#cb2-127" aria-hidden="true" tabindex="-1"></a>        plt.subplot(n_row, n_col, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb2-128"><a href="#cb2-128" aria-hidden="true" tabindex="-1"></a>        plt.imshow(images[i].reshape((h, w)), cmap<span class="op">=</span>plt.cm.gray)</span>
<span id="cb2-129"><a href="#cb2-129" aria-hidden="true" tabindex="-1"></a>        plt.title(titles[i], size<span class="op">=</span><span class="dv">12</span>)</span>
<span id="cb2-130"><a href="#cb2-130" aria-hidden="true" tabindex="-1"></a>        plt.xticks(())</span>
<span id="cb2-131"><a href="#cb2-131" aria-hidden="true" tabindex="-1"></a>        plt.yticks(())</span>
<span id="cb2-132"><a href="#cb2-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-133"><a href="#cb2-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-134"><a href="#cb2-134" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-135"><a href="#cb2-135" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the result of the prediction on a portion of the test set</span></span>
<span id="cb2-136"><a href="#cb2-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-137"><a href="#cb2-137" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-138"><a href="#cb2-138" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> title(y_pred, y_test, target_names, i):</span>
<span id="cb2-139"><a href="#cb2-139" aria-hidden="true" tabindex="-1"></a>    pred_name <span class="op">=</span> target_names[y_pred[i]].rsplit(<span class="st">&quot; &quot;</span>, <span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb2-140"><a href="#cb2-140" aria-hidden="true" tabindex="-1"></a>    true_name <span class="op">=</span> target_names[y_test[i]].rsplit(<span class="st">&quot; &quot;</span>, <span class="dv">1</span>)[<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb2-141"><a href="#cb2-141" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&quot;predicted: </span><span class="sc">%s</span><span class="ch">\n</span><span class="st">true:      </span><span class="sc">%s</span><span class="st">&quot;</span> <span class="op">%</span> (pred_name, true_name)</span>
<span id="cb2-142"><a href="#cb2-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-143"><a href="#cb2-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-144"><a href="#cb2-144" aria-hidden="true" tabindex="-1"></a>prediction_titles <span class="op">=</span> [</span>
<span id="cb2-145"><a href="#cb2-145" aria-hidden="true" tabindex="-1"></a>    title(y_pred, y_test, target_names, i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(y_pred.shape[<span class="dv">0</span>])</span>
<span id="cb2-146"><a href="#cb2-146" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb2-147"><a href="#cb2-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-148"><a href="#cb2-148" aria-hidden="true" tabindex="-1"></a>plot_gallery(X_test, prediction_titles, h, w)</span>
<span id="cb2-149"><a href="#cb2-149" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-150"><a href="#cb2-150" aria-hidden="true" tabindex="-1"></a><span class="co"># plot the gallery of the most significative eigenfaces</span></span>
<span id="cb2-151"><a href="#cb2-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-152"><a href="#cb2-152" aria-hidden="true" tabindex="-1"></a>eigenface_titles <span class="op">=</span> [<span class="st">&quot;eigenface </span><span class="sc">%d</span><span class="st">&quot;</span> <span class="op">%</span> i <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(eigenfaces.shape[<span class="dv">0</span>])]</span>
<span id="cb2-153"><a href="#cb2-153" aria-hidden="true" tabindex="-1"></a>plot_gallery(eigenfaces, eigenface_titles, h, w)</span>
<span id="cb2-154"><a href="#cb2-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-155"><a href="#cb2-155" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb2-156"><a href="#cb2-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-157"><a href="#cb2-157" aria-hidden="true" tabindex="-1"></a><span class="co"># %%</span></span>
<span id="cb2-158"><a href="#cb2-158" aria-hidden="true" tabindex="-1"></a><span class="co"># Face recognition problem would be much more effectively solved by training</span></span>
<span id="cb2-159"><a href="#cb2-159" aria-hidden="true" tabindex="-1"></a><span class="co"># convolutional neural networks but this family of models is outside of the scope of</span></span>
<span id="cb2-160"><a href="#cb2-160" aria-hidden="true" tabindex="-1"></a><span class="co"># the scikit-learn library. Interested readers should instead try to use pytorch or</span></span>
<span id="cb2-161"><a href="#cb2-161" aria-hidden="true" tabindex="-1"></a><span class="co"># tensorflow to implement such models.</span></span></code></pre></div>
<p><a
href="https://scikit-learn.org/1.7/_images/plot_face_recognition_1.png" target="_blank"><img
src="https://scikit-learn.org/1.7/_images/plot_face_recognition_1.png"
alt="../../_images/plot_face_recognition_1.png" /></a></p>
<p><strong>Prediction</strong></p>
<p><a
href="https://scikit-learn.org/1.7/_images/plot_face_recognition_2.png" target="_blank"><img
src="https://scikit-learn.org/1.7/_images/plot_face_recognition_2.png"
alt="../../_images/plot_face_recognition_2.png" /></a></p>
<p><strong>Eigenfaces</strong></p>
<p>Expected results for the top 5 most represented people in the
dataset:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>                   precision    recall  f1<span class="op">-</span>score   support</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>Gerhard_Schroeder       <span class="fl">0.91</span>      <span class="fl">0.75</span>      <span class="fl">0.82</span>        <span class="dv">28</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  Donald_Rumsfeld       <span class="fl">0.84</span>      <span class="fl">0.82</span>      <span class="fl">0.83</span>        <span class="dv">33</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>       Tony_Blair       <span class="fl">0.65</span>      <span class="fl">0.82</span>      <span class="fl">0.73</span>        <span class="dv">34</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>     Colin_Powell       <span class="fl">0.78</span>      <span class="fl">0.88</span>      <span class="fl">0.83</span>        <span class="dv">58</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    George_W_Bush       <span class="fl">0.93</span>      <span class="fl">0.86</span>      <span class="fl">0.90</span>       <span class="dv">129</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>      avg <span class="op">/</span> total       <span class="fl">0.86</span>      <span class="fl">0.84</span>      <span class="fl">0.85</span>       <span class="dv">282</span></span></code></pre></div>
<h2 id="open-problem-stock-market-structure">Open problem: Stock Market
Structure</h2>
<p>Can we predict the variation in stock prices for Google over a given
time frame?</p>
<p><a
href="https://scikit-learn.org/1.7/auto_examples/applications/plot_stock_market.html#stock-market" target="_blank">Learning
a graph structure</a></p>
<h2 id="enhanced-pipelining-features-in-scikit-learn-1.7">Enhanced
Pipelining Features in scikit-learn 1.7</h2>
<p>Since this tutorial was originally written for scikit-learn 1.4,
several enhancements have been made to pipelining capabilities:</p>
<h3 id="enhanced-array-api-support-for-pipelines">Enhanced Array API
Support for Pipelines</h3>
<p>scikit-learn 1.7 now supports Array API-compliant inputs in
pipelines, making it easier to work with data from libraries like
PyTorch and CuPy:</p>
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">import</span> torch</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="co"># Works with PyTorch tensors</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> X <span class="op">=</span> torch.tensor([[<span class="dv">1</span>, <span class="dv">2</span>], [<span class="dv">3</span>, <span class="dv">4</span>], [<span class="dv">5</span>, <span class="dv">6</span>], [<span class="dv">7</span>, <span class="dv">8</span>]])</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> y <span class="op">=</span> torch.tensor([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>])</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="co"># Pipeline with PyTorch tensors</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> pipe <span class="op">=</span> Pipeline([</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;scaler&#39;</span>, StandardScaler()),</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;pca&#39;</span>, PCA(n_components<span class="op">=</span><span class="dv">1</span>)),</span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;svm&#39;</span>, SVC())</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>... ])</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> pipe.fit(X, y)</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> predictions <span class="op">=</span> pipe.predict(X)</span></code></pre></div>
<h3 id="enhanced-sparse-data-support-in-pipelines">Enhanced Sparse Data
Support in Pipelines</h3>
<p>All pipeline components now support both traditional sparse matrices
(<code>scipy.sparse.spmatrix</code>) and the newer sparse arrays
(<code>scipy.sparse.sparray</code>):</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> scipy.sparse <span class="im">import</span> csr_array</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.feature_selection <span class="im">import</span> SelectKBest</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.linear_model <span class="im">import</span> LogisticRegression</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> X_sparse <span class="op">=</span> csr_array([[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>], [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>]])</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> y <span class="op">=</span> [<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>]</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="co"># Pipeline with sparse arrays</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> pipe <span class="op">=</span> Pipeline([</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;scaler&#39;</span>, StandardScaler()),</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;selector&#39;</span>, SelectKBest(k<span class="op">=</span><span class="dv">2</span>)),</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;classifier&#39;</span>, LogisticRegression())</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>... ])</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> pipe.fit(X_sparse, y)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> predictions <span class="op">=</span> pipe.predict(X_sparse)</span></code></pre></div>
<h3 id="enhanced-metadata-routing-for-pipelines">Enhanced Metadata
Routing for Pipelines</h3>
<p>scikit-learn 1.7 includes improved metadata routing that ensures
proper handling of metadata (like sample weights) when used within
pipelines:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.ensemble <span class="im">import</span> HistGradientBoostingClassifier</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> X <span class="op">=</span> np.random.randn(<span class="dv">100</span>, <span class="dv">10</span>)</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> y <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">100</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> sample_weights <span class="op">=</span> np.random.rand(<span class="dv">100</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="co"># Pipeline with metadata routing</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> pipe <span class="op">=</span> Pipeline([</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;scaler&#39;</span>, StandardScaler()),</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;classifier&#39;</span>, HistGradientBoostingClassifier(enable_metadata_routing<span class="op">=</span><span class="va">True</span>))</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>... ])</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> pipe.fit(X, y, classifier__sample_weight<span class="op">=</span>sample_weights)</span></code></pre></div>
<h3 id="enhanced-pipeline-visualization">Enhanced Pipeline
Visualization</h3>
<p>Pipelines now have improved HTML representation in Jupyter notebooks,
showing all parameters with non-default values highlighted:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> pipe <span class="op">=</span> Pipeline([</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;scaler&#39;</span>, StandardScaler()),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;pca&#39;</span>, PCA(n_components<span class="op">=</span><span class="dv">5</span>)),</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;svm&#39;</span>, SVC(C<span class="op">=</span><span class="dv">10</span>, gamma<span class="op">=</span><span class="fl">0.1</span>))</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>... ])</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> pipe  <span class="co"># In Jupyter, this shows enhanced HTML representation</span></span></code></pre></div>
<h3 id="enhanced-cross-validation-with-pipelines">Enhanced
Cross-Validation with Pipelines</h3>
<p>Pipeline cross-validation now supports more sophisticated scoring and
evaluation methods:</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_validate</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="im">from</span> sklearn.svm <span class="im">import</span> SVC</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> pipe <span class="op">=</span> Pipeline([</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;scaler&#39;</span>, StandardScaler()),</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;pca&#39;</span>, PCA(n_components<span class="op">=</span><span class="dv">10</span>)),</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>...     (<span class="st">&#39;svm&#39;</span>, SVC())</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>... ])</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> <span class="co"># Enhanced cross-validation with multiple metrics</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="op">&gt;&gt;&gt;</span> cv_results <span class="op">=</span> cross_validate(pipe, X, y, cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>...                            scoring<span class="op">=</span>[<span class="st">&#39;accuracy&#39;</span>, <span class="st">&#39;precision&#39;</span>, <span class="st">&#39;recall&#39;</span>, <span class="st">&#39;f1&#39;</span>])</span></code></pre></div>
<p>These enhancements maintain full backward compatibility while
providing more flexibility and power for pipeline construction and
usage.</p>
<hr />
<p>This original version of this tutorial was written by scikit-learn
developers under the <a
href="https://opensource.org/license/BSD-3-clause" target="_blank">BSD License</a>.</p>
<hr />
<p>The code examples and text were updated for scikit-learn version 1.7
by Brian Bird using Claude Sonet 4, 10/19/2025</p>
<hr />
</body>
</html>
